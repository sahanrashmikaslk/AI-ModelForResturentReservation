{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Head Count on 2024-04-19 at 21:00:00: 0\n",
      "Most Demanded Table on 2024-04-19 at 21:00:00: None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dummy data\n",
    "dummy_df = pd.read_csv('dummy_reservations.csv')\n",
    "\n",
    "# Function to predict total head count and most demanded table at a given date and time\n",
    "def predict_head_count_and_demanded_table(df, date, time):\n",
    "    # Convert date and time to the appropriate format\n",
    "    date = pd.to_datetime(date).date()\n",
    "    time = pd.to_datetime(time).time()\n",
    "    \n",
    "    # Filter the data for the given date and time\n",
    "    filtered_df = df[(pd.to_datetime(df['date']).dt.date == date) & (pd.to_datetime(df['time'], format='%H:%M:%S').dt.time == time)]\n",
    "    \n",
    "    # Predict total head count\n",
    "    total_head_count = filtered_df['head_count'].sum()\n",
    "    \n",
    "    # Identify the most demanded table\n",
    "    most_demanded_table = filtered_df['unit_id'].value_counts().idxmax() if not filtered_df.empty else None\n",
    "    \n",
    "    return total_head_count, most_demanded_table\n",
    "\n",
    "# Example usage\n",
    "date = '2024-04-19'\n",
    "time = '21:00:00'\n",
    "total_head_count, most_demanded_table = predict_head_count_and_demanded_table(dummy_df, date, time)\n",
    "\n",
    "print(f\"Total Head Count on {date} at {time}: {total_head_count}\")\n",
    "print(f\"Most Demanded Table on {date} at {time}: {most_demanded_table}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Seat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16228\\3137154091.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mX_train_cls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_cls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_unit_id_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_unit_id_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_unit_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;31m# Train Regression Model for Head Count Prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mregressor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_head_count_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;31m# Train Classification Model for Most Demanded Table Prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sahan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1148\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1149\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\sahan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    344\u001b[0m         \"\"\"\n\u001b[0;32m    345\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    349\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sahan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    618\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sahan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         raise ValueError(\n\u001b[0;32m   1143\u001b[0m             \u001b[1;33mf\"\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mestimator_name\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m requires y to be passed, but the target y is None\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1146\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1147\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sahan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    912\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    917\u001b[0m                 raise ValueError(\n\u001b[0;32m    918\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m                 \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sahan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sahan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2082\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m         if (\n\u001b[0;32m   2086\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2087\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Seat'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# Load the dummy data\n",
    "dummy_df = pd.read_csv('dummy_reservations.csv')\n",
    "\n",
    "# Data Preparation\n",
    "def prepare_data(df):\n",
    "    # Convert date and time to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S').dt.time\n",
    "    \n",
    "    # Extract features from date and time\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['hour'] = pd.to_datetime(df['time'], format='%H:%M:%S').dt.hour\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le_unit_type = LabelEncoder()\n",
    "    df['unit_type'] = le_unit_type.fit_transform(df['unit_type'])\n",
    "    \n",
    "    le_special_req = LabelEncoder()\n",
    "    df['special_req'] = le_special_req.fit_transform(df['special_req'])\n",
    "    \n",
    "    le_status = LabelEncoder()\n",
    "    df['status'] = le_status.fit_transform(df['status'])\n",
    "    \n",
    "    return df, le_unit_type, le_special_req, le_status\n",
    "\n",
    "# Prepare data\n",
    "dummy_df, le_unit_type, le_special_req, le_status = prepare_data(dummy_df)\n",
    "\n",
    "# Split data into features and target variables\n",
    "X = dummy_df[['unit_id', 'unit_type', 'day', 'month', 'hour', 'host_user', 'option1', 'prop_id', 'reserve_code', 'slot_length', 'slot_minutes', 'special_req', 'status', 'time_slots', 'user_id']]\n",
    "y_head_count = dummy_df['head_count']\n",
    "y_unit_id = dummy_df['unit_id']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_head_count_train, y_head_count_test = train_test_split(X, y_head_count, test_size=0.2, random_state=42)\n",
    "X_train_cls, X_test_cls, y_unit_id_train, y_unit_id_test = train_test_split(X, y_unit_id, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Regression Model for Head Count Prediction\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "regressor.fit(X_train, y_head_count_train)\n",
    "\n",
    "# Train Classification Model for Most Demanded Table Prediction\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train_cls, y_unit_id_train)\n",
    "\n",
    "# Predict Total Head Count\n",
    "y_head_count_pred = regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_head_count_test, y_head_count_pred)\n",
    "print(f\"Mean Squared Error for Head Count Prediction: {mse}\")\n",
    "\n",
    "# Predict Most Demanded Table\n",
    "y_unit_id_pred = classifier.predict(X_test_cls)\n",
    "accuracy = accuracy_score(y_unit_id_test, y_unit_id_pred)\n",
    "print(f\"Accuracy for Most Demanded Table Prediction: {accuracy}\")\n",
    "\n",
    "# Function to predict total head count and most demanded table at a given date and time\n",
    "def predict_head_count_and_demanded_table(df, date, time):\n",
    "    # Prepare input data\n",
    "    date = pd.to_datetime(date)\n",
    "    time = pd.to_datetime(time, format='%H:%M:%S').time()\n",
    "    \n",
    "    day = date.day\n",
    "    month = date.month\n",
    "    hour = pd.to_datetime(time, format='%H:%M:%S').hour\n",
    "    \n",
    "    # Create a single row dataframe for prediction\n",
    "    input_data = {\n",
    "        'unit_id': [1],  # Dummy value, not used for prediction\n",
    "        'unit_type': [0],  # Dummy value, replace with appropriate encoded value\n",
    "        'day': [day],\n",
    "        'month': [month],\n",
    "        'hour': [hour],\n",
    "        'host_user': [100000],  # Dummy value, not used for prediction\n",
    "        'option1': [None],  # Dummy value, replace with appropriate value\n",
    "        'prop_id': [1],  # Dummy value, not used for prediction\n",
    "        'reserve_code': [1],  # Dummy value, not used for prediction\n",
    "        'slot_length': [10],  # Dummy value, replace with appropriate value\n",
    "        'slot_minutes': [30],  # Dummy value, replace with appropriate value\n",
    "        'special_req': [0],  # Dummy value, replace with appropriate encoded value\n",
    "        'status': [0],  # Dummy value, replace with appropriate encoded value\n",
    "        'time_slots': [1],  # Dummy value, not used for prediction\n",
    "        'user_id': [1000]  # Dummy value, not used for prediction\n",
    "    }\n",
    "    \n",
    "    input_df = pd.DataFrame(input_data)\n",
    "    \n",
    "    # Predict total head count\n",
    "    total_head_count = regressor.predict(input_df)[0]\n",
    "    \n",
    "    # Predict most demanded table\n",
    "    most_demanded_table = classifier.predict(input_df)[0]\n",
    "    \n",
    "    return total_head_count, most_demanded_table\n",
    "\n",
    "# Example usage\n",
    "date = '2024-04-19'\n",
    "time = '21:00:00'\n",
    "total_head_count, most_demanded_table = predict_head_count_and_demanded_table(dummy_df, date, time)\n",
    "\n",
    "print(f\"Total Head Count on {date} at {time}: {total_head_count}\")\n",
    "print(f\"Most Demanded Table on {date} at {time}: {most_demanded_table}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# Load the dummy data\n",
    "dummy_df = pd.read_csv('dummy_reservations.csv')\n",
    "\n",
    "# Data Preparation\n",
    "def prepare_data(df):\n",
    "    # Convert date and time to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['time'] = pd.to_datetime(df['time'], format='%H:%M:%S').dt.time\n",
    "    \n",
    "    # Extract features from date and time\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['hour'] = pd.to_datetime(df['time'], format='%H:%M:%S').dt.hour\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    le_unit_type = LabelEncoder()\n",
    "    df['unit_type'] = le_unit_type.fit_transform(df['unit_type'])\n",
    "    \n",
    "    le_special_req = LabelEncoder()\n",
    "    df['special_req'] = le_special_req.fit_transform(df['special_req'])\n",
    "    \n",
    "    le_status = LabelEncoder()\n",
    "    df['status'] = le_status.fit_transform(df['status'])\n",
    "    \n",
    "    le_option1 = LabelEncoder()\n",
    "    df['option1'] = le_option1.fit_transform(df['option1'])\n",
    "    \n",
    "    return df, le_unit_type, le_special_req, le_status, le_option1\n",
    "\n",
    "# Prepare data\n",
    "dummy_df, le_unit_type, le_special_req, le_status, le_option1 = prepare_data(dummy_df)\n",
    "\n",
    "# Split data into features and target variables\n",
    "X = dummy_df[['unit_id', 'unit_type', 'day', 'month', 'hour', 'host_user', 'option1', 'prop_id', 'slot_length', 'slot_minutes', 'special_req', 'status', 'time_slots', 'user_id']]\n",
    "y_head_count = dummy_df['head_count']\n",
    "y_unit_id = dummy_df['unit_id']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_head_count_train, y_head_count_test = train_test_split(X, y_head_count, test_size=0.2, random_state=42)\n",
    "X_train_cls, X_test_cls, y_unit_id_train, y_unit_id_test = train_test_split(X, y_unit_id, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Regression Model for Head Count Prediction\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "regressor.fit(X_train, y_head_count_train)\n",
    "\n",
    "# Train Classification Model for Most Demanded Table Prediction\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train_cls, y_unit_id_train)\n",
    "\n",
    "# Predict Total Head Count\n",
    "y_head_count_pred = regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_head_count_test, y_head_count_pred)\n",
    "print(f\"Mean Squared Error for Head Count Prediction: {mse}\")\n",
    "\n",
    "# Predict Most Demanded Table\n",
    "y_unit_id_pred = classifier.predict(X_test_cls)\n",
    "accuracy = accuracy_score(y_unit_id_test, y_unit_id_pred)\n",
    "print(f\"Accuracy for Most Demanded Table Prediction: {accuracy}\")\n",
    "\n",
    "# Function to predict total head count and most demanded table at a given date and time\n",
    "def predict_head_count_and_demanded_table(df, date, time):\n",
    "    # Prepare input data\n",
    "    date = pd.to_datetime(date)\n",
    "    time = pd.to_datetime(time, format='%H:%M:%S').time()\n",
    "    \n",
    "    day = date.day\n",
    "    month = date.month\n",
    "    hour = pd.to_datetime(time, format='%H:%M:%S').hour\n",
    "    \n",
    "    # Create a single row dataframe for prediction\n",
    "    input_data = {\n",
    "        'unit_id': [1],  # Dummy value, not used for prediction\n",
    "        'unit_type': [0],  # Dummy value, replace with appropriate encoded value\n",
    "        'day': [day],\n",
    "        'month': [month],\n",
    "        'hour': [hour],\n",
    "        'host_user': [100000],  # Dummy value, not used for prediction\n",
    "        'option1': [0],  # Dummy value, replace with appropriate encoded value\n",
    "        'prop_id': [1],  # Dummy value, not used for prediction\n",
    "        'slot_length': [10],  # Dummy value, replace with appropriate value\n",
    "        'slot_minutes': [30],  # Dummy value, replace with appropriate value\n",
    "        'special_req': [0],  # Dummy value, replace with appropriate encoded value\n",
    "        'status': [0],  # Dummy value, replace with appropriate encoded value\n",
    "        'time_slots': [1],  # Dummy value, not used for prediction\n",
    "        'user_id': [1000]  # Dummy value, not used for prediction\n",
    "    }\n",
    "    \n",
    "    input_df = pd.DataFrame(input_data)\n",
    "    \n",
    "    # Predict total head count\n",
    "    total_head_count = regressor.predict(input_df)[0]\n",
    "    \n",
    "    # Predict most demanded table\n",
    "    most_demanded_table = classifier.predict(input_df)[0]\n",
    "    \n",
    "    return total_head_count, most_demanded_table\n",
    "\n",
    "# Example usage\n",
    "date = '2024-04-19'\n",
    "time = '21:00:00'\n",
    "total_head_count, most_demanded_table = predict_head_count_and_demanded_table(dummy_df, date, time)\n",
    "\n",
    "print(f\"Total Head Count on {date} at {time}: {total_head_count}\")\n",
    "print(f\"Most Demanded Table on {date} at {time}: {most_demanded_table}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
